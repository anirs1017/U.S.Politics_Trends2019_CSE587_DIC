{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIC Lab 2 - NYT Data Extraction\n",
    "\n",
    "Submitted by Aniruddha Sinha (asinha6@buffalo.edu, 50289428) and Shashank Dhar (sdhar2@buffalo.edu, 50289718)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary librariers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nytimesarticle import articleAPI\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = articleAPI('TH9879vPehVp9QkpL3xD1OcRUfDZB6Uc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to extract URLs from json file achieved after Article Search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getURL(articles):\n",
    "    \n",
    "    url = []\n",
    "    \n",
    "    for item in articles['response']['docs']:\n",
    "        url.append(item['web_url'])\n",
    "    \n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to clean data - remove all JS and CSS scripts, and get only meaningful content. Using Beautiful Soup 4 in this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanHTMLData(requested):\n",
    "    \n",
    "    soup = BeautifulSoup(requested.content, \"html.parser\")\n",
    "    \n",
    "    text = []\n",
    "    paras = soup.find_all(\"p\")\n",
    "    \n",
    "    for i in range(len(paras)):\n",
    "        if paras[i].text!='Advertisement' and paras[i].text!='Supposed by':\n",
    "            text.append(paras[i].text)\n",
    "            \n",
    "    HTML_text = \"  \".join(text)\n",
    "    \n",
    "    return HTML_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following function calls all the functions, and searches for articles based on the input tags, derives URLs and writes the content to new text files for each tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractNYTData(tags):\n",
    "    for tag in tags:\n",
    "        for i in range(10):\n",
    "            if i==0:\n",
    "                articles = api.search(q = tag, begin_date = 20190101)\n",
    "            else:\n",
    "                articles = api.search(q = tag, begin_date = 20190101, page = i)\n",
    "            URL = getURL(articles)\n",
    "            createTextFile(tag, URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to write the page content to the text files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTextFile(tag, URL):\n",
    "    f = open(\"NYT_data\"+ tag + \".txt\", \"a+\", encoding=\"utf-8\")\n",
    "    \n",
    "    for i in range(len(URL)):\n",
    "        r = requests.get(URL[i])\n",
    "        content = cleanHTMLData(r)\n",
    "        f.write(content)\n",
    "    print (\"\\n\\nData written to file successfully.\")    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the tags and call all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data written to file successfully.\n",
      "\n",
      "\n",
      "Data written to file successfully.\n",
      "\n",
      "\n",
      "Data written to file successfully.\n",
      "\n",
      "\n",
      "Data written to file successfully.\n",
      "\n",
      "\n",
      "Data written to file successfully.\n",
      "\n",
      "\n",
      "Data written to file successfully.\n",
      "\n",
      "\n",
      "Data written to file successfully.\n",
      "\n",
      "\n",
      "Data written to file successfully.\n",
      "\n",
      "\n",
      "Data written to file successfully.\n",
      "\n",
      "\n",
      "Data written to file successfully.\n",
      "\n",
      "\n",
      "Data written to file successfully.\n",
      "\n",
      "\n",
      "Data written to file successfully.\n",
      "\n",
      "\n",
      "Data written to file successfully.\n",
      "\n",
      "\n",
      "Data written to file successfully.\n",
      "\n",
      "\n",
      "Data written to file successfully.\n",
      "\n",
      "\n",
      "Data written to file successfully.\n",
      "\n",
      "\n",
      "Data written to file successfully.\n",
      "\n",
      "\n",
      "Data written to file successfully.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'response'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c1eae3a28371>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Trump\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Presidential Campaign\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Mueller\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Democrats\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"FOX news\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mextractNYTData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-5da1c2f9e54b>\u001b[0m in \u001b[0;36mextractNYTData\u001b[1;34m(tags)\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[0marticles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20190101\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mURL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetURL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mcreateTextFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mURL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-ea693fa1e4b5>\u001b[0m in \u001b[0;36mgetURL\u001b[1;34m(articles)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marticles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'response'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'docs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0murl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'web_url'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'response'"
     ]
    }
   ],
   "source": [
    "tags = [\"Trump\", \"Presidential campaign\", \"Mueller\", \"Democrats\", \"FOX news\", \"Buttigieg\"]\n",
    "extractNYTData(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
